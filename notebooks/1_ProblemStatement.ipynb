{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*1_Problem_Statement.ipynb (this file)*\n",
    "\n",
    "## Problem statement (AI-Software Overall Hypothesis)\n",
    "\n",
    "**By analyzing a combination of supply chain dynamics, shipping times, carriers, supplier locations, production volumes, routes, and shipped product features, and providing supply chain teams with a chatbot for easy real-time tracking of shipments, along with an integrated tool to stay up-to-date with relevant news from various webpages, we can predict transportation costs and enhance decision-making towards supply chain expense management while keeping operations aligned with the latest industry standards and insights.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sources Overview and Feature Definition\n",
    "\n",
    "In this section, we will define and detail the data sources utilized for each specific feature of the AI-driven software solution tailored for supply chain optimization.\n",
    "\n",
    "1.- **Supply Chain Public Dataset (Kaggle)**\n",
    "\n",
    "We are leveraging a dataset specifically tailored for supply chain analysis, available on [Kaggle](https://www.kaggle.com/datasets/harshsingh2209/supply-chain-analysis/download?datasetVersionNumber=1). This dataset provides a solid foundation for developing our predictive pricing model. The dataset's close alignment with the client's actual data makes it an ideal choice for this stage. As we progress, we plan to conduct further tests and integrate ETL (Extract, Transform, Load) processes with the client's databases, contingent upon obtaining the required data access permissions.\n",
    "\n",
    "With this data, we plan to implement a feature that focuses on predictive price modeling. This feature will identify cargo and shipments likely to incur higher costs and establish an alert system. Accessible directly through our software, this system will inform users about which shipments require closer attention or allow them to select a specific shipment to predict its price.\n",
    "\n",
    "2.- **Client's Operations DDBB (AWS RDS - MySQL Instance)**\n",
    "\n",
    "...\n",
    "With this data, we plan to integrate a feature for real-time shipment tracking accesible from instant messaging applications for convenience, etc. ...\n",
    "...\n",
    "\n",
    "\n",
    "3.- **Real-Time Supply Chain and Logistic News (Web Scrapping)**\n",
    "\n",
    "We are aggregating news from three primary sources in the air and maritime transport sectors. This initiative enables us to gather critical information for decision-making processes and enhances our understanding of current industry dynamics.\n",
    "\n",
    "- [Air Cargo News](https://www.aircargonews.net/)\n",
    "- [Maritime Logistics Professional](https://www.maritimelogisticsprofessional.com)\n",
    "- [Seatrade Maritime](https://www.seatrade-maritime.com/)\n",
    "\n",
    "The primary data extracted from these websites include news titles, text and a link to the full article, categorized into 'Global News' and 'LATAM News' to cater to user preferences.\n",
    "\n",
    "With this data, we are developing a reporting feature that transforms the responsiveness and strategic decision-making capabilities of supply chain managers. The tool leverages NLP and AI to provide predictive insights into disruptions in maritime and air logistics. Users can interact with it in several ways:\n",
    "\n",
    "- Choose the mode of transport: 'üö¢ Maritime' or '‚úàÔ∏è Air'\n",
    "- Select the geographical focus: 'üåê Global' or 'üåé South America'\n",
    "- Specify the type of news: 'Regulation', 'Issues', 'Supply Chain', etc.\n",
    "- Set the number of news articles to display, from 1 to 10\n",
    "\n",
    "**Hugging Face Model Integration:**\n",
    "Using a Hugging Face BERT model, the feture categorizes news and offers three daily recommendations ('Risks', 'Opportunities', and 'General').\n",
    "\n",
    "**Premium Option:**\n",
    "The premium layer of the feature provides:\n",
    "- Translated summaries of news articles in Spanish\n",
    "- Concise key point summaries for a business audience, limited to 350 characters\n",
    "- In-depth analysis of the article's impact on maritime logistics, port operations, and supply chain management, specifically focusing on Latin America, labeled 'Impacto en LATAM', limited to 500 characters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*2_data_wrangling.ipynb*\n",
    "\n",
    "## Stages:\n",
    "\n",
    "1. Handle missing values\n",
    "2. Define categorical features\n",
    "3. Perform feature engineering\n",
    "4. List insights for the Exploratory Data Analysis\n",
    "5. Define the data transformations needed\n",
    "\n",
    "## Output:\n",
    "\n",
    "Dataset prepared for EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*3_EDA.ipynb*\n",
    "\n",
    "## Stages:\n",
    "\n",
    "1. Data Wrangling Dataset Ingestion\n",
    "2. Analyze categorical and numerical features\n",
    "3. Select features based on their correlations\n",
    "4. Select features and the target variable\n",
    "5. Examine the distribution of numerical features\n",
    "6. Select features based on their correlations\n",
    "7. Re-define steps in data wrangling stages (if applicable)\n",
    "8. Clean the dataset for modeling\n",
    "\n",
    "## Output:\n",
    "\n",
    "Dataset for modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*4_modeling.ipynb*\n",
    "\n",
    "## Stages:\n",
    "\n",
    "1. EDA Dataset Ingestion\n",
    "2. Choose Model Type\n",
    "3. Train/Test Phase\n",
    "4. Save Intermediate Datasets\n",
    "5. Model Evaluation Metrics\n",
    "6. Try Different ML Models\n",
    "7. Pick a Useful Metric\n",
    "8. Condense Models and Metrics\n",
    "9. Visualization of Performance Plots\n",
    "10. Saving the Model\n",
    "\n",
    "## Output:\n",
    "\n",
    ".pkl file model for later usage in pipelines and platform integration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Deploment*\n",
    "\n",
    "Predictive feature integration with software platform."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
